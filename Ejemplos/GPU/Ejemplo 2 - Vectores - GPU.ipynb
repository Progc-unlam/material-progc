{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zw-Vno_15t-E"
      },
      "source": [
        "# Programación Concurrente - Ejercicio 2\n",
        "\n",
        "Para este ejercicio se realizarán practicas con GPGPU. En esta parte, se planificarán los kernels del GPU, con hilos sobre $1$ multi-dimensión. El tema que se utilizará es la suma de dos vectores. El algoritmo está basado en la función axpy nivel 1[3], de la biblioteca BLAS[4] que resuelve la ecuación:\n",
        "\n",
        "<center>$Y=\\alpha X + Y$</center>\n",
        "\n",
        "Su objetivo es enseñar a los alumnos como se utiliza Python [2] la plataforma Colab[1] y CUDA[5,6]. Mostrando el funcionamiento y granularidad (grilla, bloque, warps) de sobre una dimensión (x)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1.1. Preguntas del ejercicio\n",
        "a) El programa del punto 3.1.2 se encuentra dividido en bloques, que se identifican con nombres de colores. El problema consiste en ordenar los bloques, ya que se encuentran desordenados. Para ello, haga foco en cada celda y utilice las flechas $\\uparrow$ y $\\downarrow$, para reorganizar los bloques según el orden correcto.\n",
        "\n",
        "Nombre del bloque | Orden correcto\n",
        "------------------|----------------\n",
        "Verde             |\n",
        "Rosa              |\n",
        "Blanco            |\n",
        "Amarillo          |\n",
        "Gris              |\n",
        "Naranja           |\n",
        "Violeta           |\n",
        "Negro             |\n",
        "Rojo              |\n",
        "Azul              |\n",
        "\n",
        "\n",
        "*Tips:* Para ejecutar todas las celdas, ocúltelas con la flecha $\\downarrow$ que está al lado del título \"3.1.2 Ejecución del programa\".\n",
        "\n",
        "\n",
        "b)¿Cómo se podría instanciar una cantidad de hilos exactamente igual al tamaño del vector?\n",
        "\n"
      ],
      "metadata": {
        "id": "nC_ZBz6V1Za8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzQaWRTtc1Zj"
      },
      "source": [
        "---\n",
        "### 2.1.3 Ejecución del programa"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------------------------\n",
        "# Inicio bloque VIOLETA\n",
        "\n",
        "x_cpu = numpy.random.randn( cantidad_N )\n",
        "x_cpu = x_cpu.astype( numpy.float32() )\n",
        "\n",
        "y_cpu = numpy.random.randn( cantidad_N )\n",
        "y_cpu = y_cpu.astype( numpy.float32() )\n",
        "\n",
        "r_cpu = numpy.empty_like( x_cpu )\n",
        "\n",
        "# Fin bloque VIOLETA\n",
        "# ------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "hxhF76_b6rgv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------------------------\n",
        "# Inicio bloque ROSA\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "tiempo_total = datetime.now()\n",
        "\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule\n",
        "\n",
        "import numpy\n",
        "\n",
        "# Definición de función que transforma el tiempo en  milisegundos\n",
        "tiempo_en_ms = lambda dt:(dt.days * 24 * 60 * 60 + dt.seconds) * 1000 + dt.microseconds / 1000.0\n",
        "\n",
        "# Fin bloque ROSA\n",
        "# ------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "B0EX0dbj6jbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z74FNbCszDmw"
      },
      "source": [
        "#---------------------------\n",
        "# Inicio bloque NARANJA\n",
        "#\n",
        "#  Armado del ambiente (Ojo)\n",
        "\n",
        "!pip install pycuda\n",
        "\n",
        "# Fin bloque NARANJA\n",
        "# ------------------------------------------------------------------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------------------------\n",
        "# Inicio bloque AMARILLO\n",
        "\n",
        "# #@title 3.1 Parámetros de ejecución { vertical-output: true }\n",
        "\n",
        "cantidad_N =   500000#@param {type: \"number\"}\n",
        "alfa =   1#@param {type: \"number\"}\n",
        "\n",
        "# Fin bloque AMARILLO\n",
        "# ------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "O0MwIh186n3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------------------------\n",
        "# Inicio bloque ROJO\n",
        "\n",
        "tiempo_gpu = datetime.now()\n",
        "\n",
        "#TODO: Ojo, con los tipos de las variables en el kernel.\n",
        "kernel( numpy.int32(cantidad_N),numpy.float32(alfa), x_gpu, y_gpu, block=( dim_hilo, 1, 1 ),grid=(dim_bloque, 1,1) )\n",
        "\n",
        "tiempo_gpu = datetime.now() - tiempo_gpu\n",
        "\n",
        "# Fin bloque ROJO\n",
        "# ------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "oFyLBzPg7EyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------------------------\n",
        "# Inicio bloque BLANCO\n",
        "\n",
        "# TODO: Falta consultar limites del GPU, para armar las dimensiones correctamente.\n",
        "dim_hilo = 256\n",
        "dim_bloque = int( (cantidad_N+dim_hilo-1) / dim_hilo )\n",
        "\n",
        "# Fin bloque BLANCO\n",
        "# ------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "g9flEJpr687d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------------------------\n",
        "# Inicio bloque VERDE\n",
        "\n",
        "# GPU - Copio el resultado desde la memoria GPU.\n",
        "cuda.memcpy_dtoh( r_cpu, y_gpu )\n",
        "\n",
        "# Fin bloque VERDE\n",
        "# ------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "pO8xdiTS7JXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------------------------\n",
        "# Inicio del bloque AZUL\n",
        "\n",
        "module = SourceModule(\"\"\"\n",
        "__global__ void kernel_axpy( int n, float alfa, float *X, float *Y )\n",
        "{\n",
        "  int idx = threadIdx.x + blockIdx.x*blockDim.x;\n",
        "  if( idx < n )\n",
        "  {\n",
        "    Y[idx]  = alfa*X[idx] + Y[idx];\n",
        "  }\n",
        "}\n",
        "\"\"\")\n",
        "# CPU - Genero la función kernel.\n",
        "kernel = module.get_function(\"kernel_axpy\")\n",
        "\n",
        "# Fin del bloque AZUL\n",
        "# ------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "al5Igv1N67kx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------------------------\n",
        "# Inicio bloque NEGRO\n",
        "\n",
        "tiempo_total = datetime.now() - tiempo_total\n",
        "\n",
        "print( \"Thread x: \", dim_hilo, \", Bloque x:\", dim_bloque )\n",
        "print( \"Cantidad de elementos: \", cantidad_N )\n",
        "print( \"Thread x: \", dim_hilo, \", Bloque x:\", dim_bloque )\n",
        "print( \"Tiempo TOTAL: \", tiempo_en_ms( tiempo_total ), \"[ms]\" )\n",
        "print( \"Tiempo GPU: \", tiempo_en_ms( tiempo_gpu   ), \"[ms]\" )\n",
        "\n",
        "# Fin bloque NEGRO\n",
        "# ------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "xBKZsSTg7LGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------------------------\n",
        "# Inicio bloque GRIS\n",
        "\n",
        "# CPU - reservo la memoria GPU.\n",
        "x_gpu = cuda.mem_alloc( x_cpu.nbytes )\n",
        "y_gpu = cuda.mem_alloc( y_cpu.nbytes )\n",
        "\n",
        "# GPU - Copio la memoria al GPU.\n",
        "cuda.memcpy_htod( x_gpu, x_cpu )\n",
        "cuda.memcpy_htod( y_gpu, y_cpu )\n",
        "\n",
        "# Fin bloque GRIS\n",
        "# ------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "5VMOeuR06wNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "----\n",
        "#Impresion de los resultados"
      ],
      "metadata": {
        "id": "2s06Nxr3Th10"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"vector X:\", x_cpu)\n",
        "print (\"vector Y:\", y_cpu)\n",
        "print (\"-----------------\")\n",
        "print (\"vector resultante\",r_cpu)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyv5w_qmSFH5",
        "outputId": "4f3bfa8f-3def-47af-91a0-f9b33c3f2b11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vector X: [ 0.05145536 -0.02254807  1.0129507  ... -2.7277622  -1.9062271\n",
            " -2.4399078 ]\n",
            "vector Y: [ 0.5704873   1.0252049  -1.2074004  ... -2.8775136  -0.4193996\n",
            "  0.19811215]\n",
            "-----------------\n",
            "vector resultante [ 0.6219427   1.0026568  -0.19444978 ... -5.605276   -2.3256266\n",
            " -2.2417955 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hn6HOCYEjyY"
      },
      "source": [
        "---\n",
        "# Bibliografia\n",
        "\n",
        "[1] MARKDOWN SYNTAX Colab: [PDF](https://github.com/wvaliente/SOA_HPC/blob/main/Documentos/markdown-cheatsheet-online.pdf)\n",
        "\n",
        "[2] Introducción a Python: [Página Colab](https://github.com/wvaliente/SOA_HPC/blob/main/Documentos/Python_Basico.ipynb)\n",
        "\n",
        "[3] Función Axpy de biblioteca BLAS: [Referencia](https://software.intel.com/content/www/us/en/develop/documentation/mkl-developer-reference-c/top/blas-and-sparse-blas-routines/blas-routines/blas-level-1-routines-and-functions/cblas-axpy.html)\n",
        "\n",
        "[4] Biblioteca BLAS: [Referencia](http://www.netlib.org/blas/)\n",
        "\n",
        "[5] Documentación PyCUDA: [WEB](https://documen.tician.de/pycuda/index.html)\n",
        "\n",
        "[6] Repositorio de PyCUDA: [WEB](https://pypi.python.org/pypi/pycuda)\n",
        "\n",
        "\n"
      ]
    }
  ]
}