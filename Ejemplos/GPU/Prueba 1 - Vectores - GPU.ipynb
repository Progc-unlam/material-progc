{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Prueba 1 - Vectores - GPU.ipynb","provenance":[{"file_id":"/v2/external/notebooks/basic_features_overview.ipynb","timestamp":1601321037647}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Zw-Vno_15t-E"},"source":["# 1 Introducción\n","El siguiente cuaderno realiza la suma de dos vectores, utilizando GPGPU. El algoritmo está basado en la función axpy nivel 1[3], de la biblioteca BLAS[4] que resuelve la ecuación:\n","<center>$Y=\\alpha X + Y$</center>\n","\n","Su objetivo es enseñar a los alumnos como se utiliza Python [2] la plataforma Colab[1] y CUDA[5,6]. Mostrando el funcionamiento y granularidad (grilla, bloque, warps) de sobre una dimensión (x)."]},{"cell_type":"markdown","metadata":{"id":"7cRnhv_7N4Pa"},"source":["---\n","# 2 Armado del ambiente\n","Instala en el cuaderno el módulo CUDA de Python."]},{"cell_type":"code","metadata":{"id":"z74FNbCszDmw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624451352647,"user_tz":180,"elapsed":102840,"user":{"displayName":"Waldo Adolfo Valiente","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgfpImr9VJB8O2-AFSk5VLoDyQeeIzmtBWwMl27IQ=s64","userId":"07720288480485820277"}},"outputId":"ddd209dd-2140-452f-ee4b-2de472a387c8"},"source":["!pip install pycuda"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting pycuda\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/56/4682a5118a234d15aa1c8768a528aac4858c7b04d2674e18d586d3dfda04/pycuda-2021.1.tar.gz (1.7MB)\n","\u001b[K     |████████████████████████████████| 1.7MB 8.8MB/s \n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Collecting mako\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/54/dbc07fbb20865d3b78fdb7cf7fa713e2cba4f87f71100074ef2dc9f9d1f7/Mako-1.1.4-py2.py3-none-any.whl (75kB)\n","\u001b[K     |████████████████████████████████| 81kB 12.3MB/s \n","\u001b[?25hCollecting pytools>=2011.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/26/c7ab098ceb4e4e3f0e66e21257a286bb455ea22af7afefbd704d9ccf324c/pytools-2021.2.7.tar.gz (63kB)\n","\u001b[K     |████████████████████████████████| 71kB 11.0MB/s \n","\u001b[?25hRequirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from pycuda) (1.4.4)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from mako->pycuda) (2.0.1)\n","Requirement already satisfied: numpy>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from pytools>=2011.2->pycuda) (1.19.5)\n","Building wheels for collected packages: pycuda\n","  Building wheel for pycuda (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pycuda: filename=pycuda-2021.1-cp37-cp37m-linux_x86_64.whl size=627610 sha256=8bf889d18823d37579cba61979aae59c80b4fc45f2c50aefe9b26c49eb135e74\n","  Stored in directory: /root/.cache/pip/wheels/d5/55/64/fd4dddcc5f1c25eebd90b5291c3769101dc978c70165685512\n","Successfully built pycuda\n","Building wheels for collected packages: pytools\n","  Building wheel for pytools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pytools: filename=pytools-2021.2.7-py2.py3-none-any.whl size=60644 sha256=c99dad016b639417671a372d4f3b2060c66d22b44a40e8f885810f36ea134a34\n","  Stored in directory: /root/.cache/pip/wheels/a0/b5/e5/e65d25997fd77729b9aa214645add18688483e48bbcbab6ffc\n","Successfully built pytools\n","Installing collected packages: mako, pytools, pycuda\n","Successfully installed mako-1.1.4 pycuda-2021.1 pytools-2021.2.7\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NzQaWRTtc1Zj"},"source":["---\n","# 3 Desarrollo\n","Ejecuta el Código CPU - GPU."]},{"cell_type":"code","metadata":{"id":"9c7mZSnu0M3m","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624451427514,"user_tz":180,"elapsed":297,"user":{"displayName":"Waldo Adolfo Valiente","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgfpImr9VJB8O2-AFSk5VLoDyQeeIzmtBWwMl27IQ=s64","userId":"07720288480485820277"}},"outputId":"5f3341f8-ea94-4564-a85d-f2a964fc925f"},"source":["# --------------------------------------------\n","#@title 3.1 Parámetros de ejecución { vertical-output: true }\n","\n","cantidad_N =   500000#@param {type: \"number\"}\n","alfa =   1#@param {type: \"number\"}\n","# --------------------------------------------\n","\n","from datetime import datetime\n","\n","tiempo_total = datetime.now()\n","\n","import pycuda.driver as cuda\n","import pycuda.autoinit\n","from pycuda.compiler import SourceModule\n","\n","import numpy\n","\n","# --------------------------------------------\n","# Definición de función que transforma el tiempo en  milisegundos \n","tiempo_en_ms = lambda dt:(dt.days * 24 * 60 * 60 + dt.seconds) * 1000 + dt.microseconds / 1000.0\n","\n","\n","# CPU - Defino la memoria de los vectores en cpu.\n","x_cpu = numpy.random.randn( cantidad_N )\n","x_cpu = x_cpu.astype( numpy.float32() )\n","\n","y_cpu = numpy.random.randn( cantidad_N )\n","y_cpu = y_cpu.astype( numpy.float32() )\n","\n","#tiempo_ini_cpu = datetime.now()\n","\n","r_cpu = numpy.empty_like( x_cpu )\n","\n","# CPU - reservo la memoria GPU.\n","x_gpu = cuda.mem_alloc( x_cpu.nbytes )\n","y_gpu = cuda.mem_alloc( y_cpu.nbytes )\n","\n","# GPU - Copio la memoria al GPU.\n","cuda.memcpy_htod( x_gpu, x_cpu )\n","cuda.memcpy_htod( y_gpu, y_cpu )\n","\n","# CPU - Defino la función kernel que ejecutará en GPU.\n","module = SourceModule(\"\"\"\n","__global__ void kernel_axpy( int n, float alfa, float *X, float *Y )\n","{\n","  int idx = threadIdx.x + blockIdx.x*blockDim.x;\n","  if( idx < n )\n","  {\n","    Y[idx]  = alfa*X[idx] + Y[idx];\n","  }\n","}\n","\"\"\") \n","# CPU - Genero la función kernel.\n","kernel = module.get_function(\"kernel_axpy\")\n","\n","tiempo_gpu = datetime.now()\n","\n","# GPU - Ejecuta el kernel.\n","# TODO: Falta consultar limites del GPU, para armar las dimensiones correctamente.\n","dim_hilo = 256\n","dim_bloque = numpy.int( (cantidad_N+dim_hilo-1) / dim_hilo )\n","print( \"Thread x: \", dim_hilo, \", Bloque x:\", dim_bloque )\n","\n","#TODO: Ojo, con los tipos de las variables en el kernel.\n","kernel( numpy.int32(cantidad_N),numpy.float32(alfa), x_gpu, y_gpu, block=( dim_hilo, 1, 1 ),grid=(dim_bloque, 1,1) )\n","\n","tiempo_gpu = datetime.now() - tiempo_gpu\n","\n","# GPU - Copio el resultado desde la memoria GPU.\n","cuda.memcpy_dtoh( r_cpu, y_gpu )\n","\n","\"\"\"\n","# CPU - Informo el resutlado.\n","print( \"------------------------------------\")\n","print( \"X: \" )\n","print( x_cpu )\n","print( \"------------------------------------\")\n","print( \"Y: \" )\n","print( y_cpu )\n","print( \"------------------------------------\")\n","print( \"R: \" )\n","print( r_cpu )\n","\"\"\"\n","\n","tiempo_total = datetime.now() - tiempo_total\n","\n","print( \"Cantidad de elementos: \", cantidad_N )\n","print( \"Thread x: \", dim_hilo, \", Bloque x:\", dim_bloque )\n","print(\"Tiempo TOTAL: \", tiempo_en_ms( tiempo_total ), \"[ms]\" )\n","print(\"Tiempo GPU: \", tiempo_en_ms( tiempo_gpu   ), \"[ms]\" )\n"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Thread x:  256 , Bloque x: 1954\n","Cantidad de elementos:  500000\n","Thread x:  256 , Bloque x: 1954\n","Tiempo TOTAL:  43.495 [ms]\n","Tiempo GPU:  0.844 [ms]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"EALIlyyG6iqP"},"source":["---\n","# 4 Tabla de pasos de ejecución del programa\n","\n","\n"," Procesador | Funciòn | Detalle\n","------------|---------|----------\n","CPU      |  @param                | Lectura del tamaño de vectores desde Colab.\n","CPU      |  import                | Importa los módulos para funcionar.\n","CPU      |  datetime.now()        | Toma el tiempo actual.\n","CPU      |  numpy.random.randn( Cantidad_N ) | Inicializa los vectoes A, B y R.\n","**GPU**  |  cuda.mem_alloc()      | Reserva la memoria en GPU.\n","**GPU**  |  cuda.memcpy_htod()    | Copia las memorias desde el CPU al GPU.\n","CPU      |  SourceModule()        | Define el código del kernel \n","CPU      |  module.get_function() | Genera la función del kernel GPU\n","CPU      |  dim_tx/dim_bx         | Calcula las dimensiones.\n","**GPU**  |  kernel()              | Ejecuta el kernel en GPU\n","CPU      |  cuda.memcpy_dtoh( )   | Copia el resultado desde GPU memoria A a CPU memoria R.\n","CPU      |  print()               | Informo los resultados.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"TzgZkrQD-UTy"},"source":["---\n","# 5 Conclusiones\n","\n","Las conclusiones son explicadas en clase....\n"]},{"cell_type":"markdown","metadata":{"id":"6hn6HOCYEjyY"},"source":["---\n","# 6 Bibliografia\n","\n","[1] MARKDOWN SYNTAX Colab: [PDF](https://github.com/wvaliente/SOA_HPC/blob/main/Documentos/markdown-cheatsheet-online.pdf)\n","\n","[2] Introducción a Python: [Página Colab](https://github.com/wvaliente/SOA_HPC/blob/main/Documentos/Python_Basico.ipynb) \n","\n","[3] Función Axpy de biblioteca BLAS: [Referencia](https://software.intel.com/content/www/us/en/develop/documentation/mkl-developer-reference-c/top/blas-and-sparse-blas-routines/blas-routines/blas-level-1-routines-and-functions/cblas-axpy.html)\n","\n","[4] Biblioteca BLAS: [Referencia](http://www.netlib.org/blas/)\n","\n","[5] Documentación PyCUDA: [WEB](https://documen.tician.de/pycuda/index.html)\n","\n","[6] Repositorio de PyCUDA: [WEB](https://pypi.python.org/pypi/pycuda)\n","\n","\n"]}]}