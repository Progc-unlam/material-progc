{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/wvaliente/SOA_HPC/blob/main/Ejercicios/Hola%20Mundo%20-%20MPI.ipynb","timestamp":1677628907493},{"file_id":"1T3PyLin0Fju037OdvJGU6zQJLVeKuoGM","timestamp":1605557651125},{"file_id":"16bSmIHD6ekaA7L_VWCqfQ7AkSB78icQA","timestamp":1605519829004},{"file_id":"https://github.com/wvaliente/SOA_HPC/blob/main/Ejercicios/Prueba%201%20-%20Vectores%20-%20CPU.ipynb","timestamp":1604955248022},{"file_id":"/v2/external/notebooks/basic_features_overview.ipynb","timestamp":1601321037647}],"private_outputs":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"th1ZsKBrRMrn"},"source":["# SOA - Ejemplos MPI\n","\n","Ejemplo de AVG  con Scatter y Gather\n"]},{"cell_type":"code","metadata":{"id":"fEbO8EXWm4mL"},"source":["code = \"\"\"\n","\n","// Author: Wes Kendall\n","// Copyright 2012 www.mpitutorial.com\n","// This code is provided freely with the tutorials on mpitutorial.com. Feel\n","// free to modify it for your own use. Any distribution of the code must\n","// either provide a link to www.mpitutorial.com or keep this header intact.\n","//\n","// Program that computes the average of an array of elements in parallel using\n","// MPI_Scatter and MPI_Gather\n","//\n","#include <stdio.h>\n","#include <stdlib.h>\n","#include <time.h>\n","#include <mpi.h>\n","#include <assert.h>\n","#include <time.h>\n","\n","#define NUM_ELEMENTS 2\n","\n","\n","// Creates an array of random numbers. Each number has a value from 0 - 1\n","float *create_rand_nums(int num_elements)\n","{\n","  float *rand_nums = (float*)malloc(sizeof(float) * num_elements);\n","  assert(rand_nums != NULL);\n","  int i;\n","  printf(\"valores array\\\\n\");\n","  for (i = 0; i < num_elements; i++) \n","  {\n","    rand_nums[i] = rand() % 5;\n","    printf(\" %f \",rand_nums[i]);\n","  }\n","  printf(\"\\\\n\");\n","  return rand_nums;\n","}\n","\n","// Computes the average of an array of numbers\n","float compute_avg(float *array, int num_elements) \n","{\n","  float sum = 0.f;\n","  int i;\n","  for (i = 0; i < num_elements; i++) \n","  {\n","    sum += array[i];\n","  }\n","  return sum / num_elements;\n","}\n","\n","int main(int argc, char** argv) \n","{\n","\n","  int num_elements_per_proc = NUM_ELEMENTS;\n","  // Seed the random number generator to get different results each time\n","  srand(time(NULL));\n","\n","  MPI_Init(NULL, NULL);\n","\n","  int world_rank;\n","  MPI_Comm_rank(MPI_COMM_WORLD, &world_rank);\n","  int world_size;\n","  MPI_Comm_size(MPI_COMM_WORLD, &world_size);\n","\n","  // Create a random array of elements on the root process. Its total\n","  // size will be the number of elements per process times the number\n","  // of processes\n","  float *rand_nums = NULL;\n","  if (world_rank == 0) {\n","    rand_nums = create_rand_nums(num_elements_per_proc * world_size);\n","  }\n","\n","  // For each process, create a buffer that will hold a subset of the entire\n","  // array\n","  float *sub_rand_nums = (float *)malloc(sizeof(float) * num_elements_per_proc);\n","  assert(sub_rand_nums != NULL);\n","\n","  // Scatter the random numbers from the root process to all processes in\n","  // the MPI world\n","  MPI_Scatter(rand_nums, num_elements_per_proc, MPI_FLOAT, sub_rand_nums,\n","              num_elements_per_proc, MPI_FLOAT, 0, MPI_COMM_WORLD);\n","\n","  // Compute the average of your subset\n","  float sub_avg = compute_avg(sub_rand_nums, num_elements_per_proc);\n","\n","  // Gather all partial averages down to the root process\n","  float *sub_avgs = NULL;\n","  if (world_rank == 0)\n","  {\n","    sub_avgs = (float *)malloc(sizeof(float) * world_size);\n","    assert(sub_avgs != NULL);\n","  }\n","  MPI_Gather(&sub_avg, 1, MPI_FLOAT, sub_avgs, 1, MPI_FLOAT, 0, MPI_COMM_WORLD);\n","\n","  // Now that we have all of the partial averages on the root, compute the\n","  // total average of all numbers. Since we are assuming each process computed\n","  // an average across an equal amount of elements, this computation will\n","  // produce the correct answer.\n","  if (world_rank == 0) \n","  {\n","    float avg = compute_avg(sub_avgs, world_size);\n","    printf(\"Avg of all elements is %f\\\\n\", avg);\n","    // Compute the average across the original data for comparison\n","    float original_data_avg =\n","      compute_avg(rand_nums, num_elements_per_proc * world_size);\n","    printf(\"Avg computed across original data is %f\\\\n\", original_data_avg);\n","  }\n","\n","  // Clean up\n","  if (world_rank == 0) \n","  {\n","    free(rand_nums);\n","    free(sub_avgs);\n","  }\n","  free(sub_rand_nums);\n","\n","  MPI_Barrier(MPI_COMM_WORLD);\n","  MPI_Finalize();\n","}\n","\n","\"\"\"\n","text_file = open(\"avg.c\", \"w\")\n","text_file.write(code)\n","text_file.close()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R2CUqGa2NSPh"},"source":["## 1.1.Compilación de código C Hola Mundo. "]},{"cell_type":"code","metadata":{"id":"xLk4a5lTnOEI"},"source":["!mpicc -o avg avg.c"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NO--9RYTNe91"},"source":["## 1.2.Ejecución Hola Mundo en MPI."]},{"cell_type":"code","metadata":{"id":"98G8IH-NnGHQ"},"source":["!mpirun --allow-run-as-root -oversubscribe -n 3 avg"],"execution_count":null,"outputs":[]}]}